{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2eaa2f",
   "metadata": {},
   "source": [
    "Разобраться с моделькой перевода (без механизма внимания) как она устроена, запустить для перевода с русского на английский (при желании можно взять другие пары языков)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcaa6436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af687787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:\\\\Мой диск\\\\Colab Notebooks\\\\NLP\\\\Lesson10'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fda7c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"rus.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de49430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    w = w.lower().strip()\n",
    "    w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Zа-яА-Я?.!,']+\", \" \", w)\n",
    "    w = w.strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa9bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:2]]  for l in lines[:num_examples]]\n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "823a8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "en, ru = create_dataset(path_to_file, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d86918d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<start> go . <end>',\n",
       " '<start> go . <end>',\n",
       " '<start> go . <end>',\n",
       " '<start> hi . <end>',\n",
       " '<start> hi . <end>',\n",
       " '<start> hi . <end>',\n",
       " '<start> hi . <end>',\n",
       " '<start> hi . <end>',\n",
       " '<start> hi . <end>',\n",
       " '<start> run ! <end>',\n",
       " '<start> run ! <end>',\n",
       " '<start> run . <end>',\n",
       " '<start> run . <end>',\n",
       " '<start> who ? <end>',\n",
       " '<start> wow ! <end>',\n",
       " '<start> wow ! <end>',\n",
       " '<start> wow ! <end>',\n",
       " '<start> wow ! <end>',\n",
       " '<start> wow ! <end>',\n",
       " '<start> wow ! <end>',\n",
       " '<start> duck ! <end>',\n",
       " '<start> fire ! <end>',\n",
       " '<start> fire ! <end>',\n",
       " '<start> help ! <end>',\n",
       " '<start> help ! <end>',\n",
       " '<start> help ! <end>',\n",
       " '<start> hide . <end>',\n",
       " '<start> hide . <end>',\n",
       " '<start> hide . <end>',\n",
       " '<start> hide . <end>',\n",
       " '<start> jump ! <end>',\n",
       " '<start> jump ! <end>',\n",
       " '<start> jump . <end>',\n",
       " '<start> jump . <end>',\n",
       " '<start> stay . <end>',\n",
       " '<start> stay . <end>',\n",
       " '<start> stay . <end>',\n",
       " '<start> stay . <end>',\n",
       " '<start> stop ! <end>',\n",
       " '<start> stop ! <end>',\n",
       " '<start> stop ! <end>',\n",
       " '<start> wait ! <end>',\n",
       " '<start> wait ! <end>',\n",
       " '<start> wait ! <end>',\n",
       " '<start> wait ! <end>',\n",
       " '<start> wait ! <end>',\n",
       " '<start> wait . <end>',\n",
       " '<start> wait . <end>',\n",
       " '<start> wait . <end>',\n",
       " '<start> do it . <end>',\n",
       " '<start> go on . <end>',\n",
       " '<start> go on . <end>',\n",
       " '<start> hello ! <end>',\n",
       " '<start> hello ! <end>',\n",
       " '<start> hello ! <end>',\n",
       " '<start> hello ! <end>',\n",
       " '<start> hurry ! <end>',\n",
       " '<start> i ran . <end>',\n",
       " '<start> i ran . <end>',\n",
       " '<start> i ran . <end>',\n",
       " '<start> i ran . <end>',\n",
       " '<start> i see . <end>',\n",
       " '<start> i see . <end>',\n",
       " '<start> i see . <end>',\n",
       " '<start> i try . <end>',\n",
       " '<start> i try . <end>',\n",
       " '<start> i try . <end>',\n",
       " '<start> i won ! <end>',\n",
       " '<start> i won ! <end>',\n",
       " '<start> i won ! <end>',\n",
       " '<start> i won ! <end>',\n",
       " '<start> oh no ! <end>',\n",
       " '<start> relax . <end>',\n",
       " '<start> relax . <end>',\n",
       " '<start> relax . <end>',\n",
       " '<start> shoot ! <end>',\n",
       " '<start> smile . <end>',\n",
       " '<start> smile . <end>',\n",
       " '<start> smile . <end>',\n",
       " '<start> smile . <end>',\n",
       " '<start> smile . <end>',\n",
       " '<start> smile . <end>',\n",
       " '<start> sorry ? <end>',\n",
       " '<start> sorry ? <end>',\n",
       " '<start> attack ! <end>',\n",
       " '<start> buy it . <end>',\n",
       " '<start> buy it . <end>',\n",
       " '<start> buy it . <end>',\n",
       " '<start> buy it . <end>',\n",
       " '<start> buy it . <end>',\n",
       " '<start> buy it . <end>',\n",
       " '<start> cheers ! <end>',\n",
       " '<start> cheers ! <end>',\n",
       " '<start> cheers ! <end>',\n",
       " '<start> cheers ! <end>',\n",
       " '<start> cheers ! <end>',\n",
       " '<start> eat it . <end>',\n",
       " '<start> eat it . <end>',\n",
       " '<start> eat it . <end>',\n",
       " '<start> eat it . <end>',\n",
       " '<start> eat it . <end>',\n",
       " '<start> eat it . <end>',\n",
       " '<start> eat up . <end>',\n",
       " '<start> freeze ! <end>',\n",
       " '<start> freeze ! <end>',\n",
       " '<start> freeze ! <end>',\n",
       " '<start> freeze ! <end>',\n",
       " '<start> get up . <end>',\n",
       " '<start> get up . <end>',\n",
       " '<start> get up . <end>',\n",
       " '<start> get up . <end>',\n",
       " '<start> go now . <end>',\n",
       " '<start> go now . <end>',\n",
       " '<start> go now . <end>',\n",
       " '<start> go now . <end>',\n",
       " '<start> go now . <end>',\n",
       " '<start> go now . <end>',\n",
       " '<start> go now . <end>',\n",
       " '<start> go now . <end>',\n",
       " '<start> go now . <end>',\n",
       " '<start> got it ! <end>',\n",
       " '<start> got it ? <end>',\n",
       " '<start> got it ? <end>',\n",
       " '<start> got it ? <end>',\n",
       " '<start> got it ? <end>',\n",
       " '<start> he ran . <end>',\n",
       " '<start> hop in . <end>',\n",
       " '<start> hop in . <end>',\n",
       " '<start> hug me . <end>',\n",
       " '<start> hug me . <end>',\n",
       " '<start> i fell . <end>',\n",
       " '<start> i fell . <end>',\n",
       " '<start> i knit . <end>',\n",
       " '<start> i know . <end>',\n",
       " '<start> i know . <end>',\n",
       " '<start> i know . <end>',\n",
       " '<start> i left . <end>',\n",
       " '<start> i left . <end>',\n",
       " '<start> i left . <end>',\n",
       " '<start> i left . <end>',\n",
       " '<start> i lied . <end>',\n",
       " '<start> i lied . <end>',\n",
       " '<start> i lost . <end>',\n",
       " '<start> i lost . <end>',\n",
       " '<start> i paid . <end>',\n",
       " '<start> i paid . <end>',\n",
       " '<start> i pass . <end>',\n",
       " '<start> i quit . <end>',\n",
       " '<start> i spit . <end>',\n",
       " '<start> i spit . <end>',\n",
       " '<start> i swim . <end>',\n",
       " '<start> i work . <end>',\n",
       " \"<start> i'm . <end>\",\n",
       " \"<start> i'm ok . <end>\",\n",
       " \"<start> i'm ok . <end>\",\n",
       " \"<start> i'm ok . <end>\",\n",
       " \"<start> i'm ok . <end>\",\n",
       " \"<start> i'm up . <end>\",\n",
       " \"<start> i'm up . <end>\",\n",
       " '<start> listen . <end>',\n",
       " '<start> listen . <end>',\n",
       " '<start> listen . <end>',\n",
       " '<start> listen . <end>',\n",
       " '<start> listen . <end>',\n",
       " '<start> listen . <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> really ? <end>',\n",
       " '<start> really ? <end>',\n",
       " '<start> really ? <end>',\n",
       " '<start> really ? <end>',\n",
       " '<start> really ? <end>',\n",
       " '<start> really ? <end>',\n",
       " '<start> really ? <end>',\n",
       " '<start> really ? <end>',\n",
       " '<start> thanks ! <end>',\n",
       " '<start> thanks ! <end>',\n",
       " '<start> try it . <end>',\n",
       " '<start> we hid . <end>',\n",
       " '<start> we ran . <end>',\n",
       " '<start> we try . <end>',\n",
       " '<start> we won . <end>',\n",
       " '<start> we won . <end>',\n",
       " '<start> why me ? <end>',\n",
       " '<start> ask tom . <end>',\n",
       " '<start> ask tom . <end>',\n",
       " '<start> ask tom . <end>',\n",
       " '<start> ask tom . <end>',\n",
       " '<start> ask tom . <end>',\n",
       " '<start> ask tom . <end>',\n",
       " '<start> ask him . <end>',\n",
       " '<start> ask him . <end>',\n",
       " '<start> ask him . <end>',\n",
       " '<start> ask him . <end>',\n",
       " '<start> awesome ! <end>',\n",
       " '<start> awesome ! <end>',\n",
       " '<start> be calm . <end>',\n",
       " '<start> be calm . <end>',\n",
       " '<start> be calm . <end>',\n",
       " '<start> be calm . <end>',\n",
       " '<start> be fair . <end>',\n",
       " '<start> be fair . <end>',\n",
       " '<start> be fair . <end>',\n",
       " '<start> be fair . <end>',\n",
       " '<start> be good . <end>',\n",
       " '<start> be kind . <end>',\n",
       " '<start> be kind . <end>',\n",
       " '<start> be kind . <end>',\n",
       " '<start> be nice . <end>',\n",
       " '<start> beat it . <end>',\n",
       " '<start> beat it . <end>',\n",
       " '<start> beat it . <end>',\n",
       " '<start> beat it . <end>',\n",
       " '<start> beat it . <end>',\n",
       " '<start> beat it . <end>',\n",
       " '<start> burn it . <end>',\n",
       " '<start> burn it . <end>',\n",
       " '<start> burn it . <end>',\n",
       " '<start> burn it . <end>',\n",
       " '<start> call me . <end>',\n",
       " '<start> call me . <end>',\n",
       " '<start> call me . <end>',\n",
       " '<start> call me . <end>',\n",
       " '<start> call us . <end>',\n",
       " '<start> call us . <end>',\n",
       " '<start> call us . <end>',\n",
       " '<start> call us . <end>',\n",
       " '<start> come in . <end>',\n",
       " '<start> come in . <end>',\n",
       " '<start> come in . <end>',\n",
       " '<start> come in . <end>',\n",
       " '<start> come in . <end>',\n",
       " '<start> come in . <end>',\n",
       " '<start> come in . <end>',\n",
       " '<start> come in . <end>',\n",
       " '<start> come in . <end>',\n",
       " '<start> come on ! <end>',\n",
       " '<start> come on ! <end>',\n",
       " '<start> come on ! <end>',\n",
       " '<start> come on . <end>',\n",
       " '<start> come on . <end>',\n",
       " '<start> come on . <end>',\n",
       " '<start> come on . <end>',\n",
       " '<start> do this . <end>',\n",
       " '<start> do this . <end>',\n",
       " '<start> drop it ! <end>',\n",
       " '<start> drop it . <end>',\n",
       " '<start> fold it . <end>',\n",
       " '<start> fold it . <end>',\n",
       " '<start> fold it . <end>',\n",
       " '<start> fold it . <end>',\n",
       " '<start> fold it . <end>',\n",
       " '<start> fold it . <end>',\n",
       " '<start> fold it . <end>',\n",
       " '<start> fold it . <end>',\n",
       " '<start> get tom . <end>',\n",
       " '<start> get out ! <end>',\n",
       " '<start> get out ! <end>',\n",
       " '<start> get out ! <end>',\n",
       " '<start> get out ! <end>',\n",
       " '<start> get out . <end>',\n",
       " '<start> get out . <end>',\n",
       " '<start> get out . <end>',\n",
       " '<start> get out . <end>',\n",
       " '<start> get out . <end>',\n",
       " '<start> go away ! <end>',\n",
       " '<start> go away ! <end>',\n",
       " '<start> go away ! <end>',\n",
       " '<start> go away ! <end>',\n",
       " '<start> go away . <end>',\n",
       " '<start> go away . <end>',\n",
       " '<start> go away . <end>',\n",
       " '<start> go away . <end>',\n",
       " '<start> go away . <end>',\n",
       " '<start> go away . <end>',\n",
       " '<start> go back . <end>',\n",
       " '<start> go back . <end>',\n",
       " '<start> go back . <end>',\n",
       " '<start> go back . <end>',\n",
       " '<start> go home . <end>',\n",
       " '<start> go home . <end>',\n",
       " '<start> go slow . <end>',\n",
       " '<start> goodbye ! <end>',\n",
       " '<start> goodbye ! <end>',\n",
       " '<start> goodbye . <end>',\n",
       " '<start> hang on . <end>',\n",
       " '<start> hang on . <end>',\n",
       " '<start> he came . <end>',\n",
       " '<start> he left . <end>',\n",
       " '<start> he left . <end>',\n",
       " '<start> he runs . <end>',\n",
       " '<start> help me ! <end>',\n",
       " '<start> help me ! <end>',\n",
       " '<start> help me . <end>',\n",
       " '<start> help me . <end>',\n",
       " '<start> help me . <end>',\n",
       " '<start> help us . <end>',\n",
       " '<start> help us . <end>',\n",
       " '<start> help us . <end>',\n",
       " '<start> help us . <end>',\n",
       " '<start> hi , tom . <end>',\n",
       " '<start> hit tom . <end>',\n",
       " '<start> hit tom . <end>',\n",
       " '<start> hit tom . <end>',\n",
       " '<start> hold it ! <end>',\n",
       " '<start> hold it ! <end>',\n",
       " '<start> hold it ! <end>',\n",
       " '<start> hold it ! <end>',\n",
       " '<start> hold it . <end>',\n",
       " '<start> hold on . <end>',\n",
       " '<start> how sad ! <end>',\n",
       " '<start> how sad ! <end>',\n",
       " '<start> hug tom . <end>',\n",
       " '<start> hug tom . <end>',\n",
       " '<start> i agree . <end>',\n",
       " '<start> i agree . <end>',\n",
       " '<start> i agree . <end>',\n",
       " '<start> i bowed . <end>',\n",
       " '<start> i cried . <end>',\n",
       " '<start> i cried . <end>',\n",
       " '<start> i dozed . <end>',\n",
       " '<start> i drove . <end>',\n",
       " '<start> i drove . <end>',\n",
       " '<start> i fired . <end>',\n",
       " '<start> i moved . <end>',\n",
       " '<start> i moved . <end>',\n",
       " '<start> i slept . <end>',\n",
       " '<start> i slept . <end>',\n",
       " '<start> i snore . <end>',\n",
       " '<start> i stood . <end>',\n",
       " '<start> i swore . <end>',\n",
       " '<start> i swore . <end>',\n",
       " '<start> i tried . <end>',\n",
       " '<start> i tried . <end>',\n",
       " '<start> i waved . <end>',\n",
       " '<start> i waved . <end>',\n",
       " \"<start> i'll go . <end>\",\n",
       " \"<start> i'll go . <end>\",\n",
       " \"<start> i'm tom . <end>\",\n",
       " \"<start> i'm bad . <end>\",\n",
       " \"<start> i'm bad . <end>\",\n",
       " \"<start> i'm fat . <end>\",\n",
       " \"<start> i'm fat . <end>\",\n",
       " \"<start> i'm fit . <end>\",\n",
       " \"<start> i'm hit ! <end>\",\n",
       " \"<start> i'm hot . <end>\",\n",
       " \"<start> i'm ill . <end>\",\n",
       " \"<start> i'm ill . <end>\",\n",
       " \"<start> i'm ill . <end>\",\n",
       " \"<start> i'm mad . <end>\",\n",
       " \"<start> i'm mad . <end>\",\n",
       " \"<start> i'm new . <end>\",\n",
       " \"<start> i'm new . <end>\",\n",
       " \"<start> i'm old . <end>\",\n",
       " \"<start> i'm old . <end>\",\n",
       " \"<start> i'm sad . <end>\",\n",
       " \"<start> i'm shy . <end>\",\n",
       " \"<start> i'm shy . <end>\",\n",
       " \"<start> i'm shy . <end>\",\n",
       " \"<start> i'm shy . <end>\",\n",
       " \"<start> i'm shy . <end>\",\n",
       " \"<start> i'm shy . <end>\",\n",
       " \"<start> i'm shy . <end>\",\n",
       " \"<start> i'm shy . <end>\",\n",
       " \"<start> i'm shy . <end>\",\n",
       " \"<start> i'm wet . <end>\",\n",
       " \"<start> i'm wet . <end>\",\n",
       " \"<start> it's ok . <end>\",\n",
       " \"<start> it's ok . <end>\",\n",
       " \"<start> it's me ! <end>\",\n",
       " \"<start> it's me ! <end>\",\n",
       " \"<start> it's me . <end>\",\n",
       " '<start> join me . <end>',\n",
       " '<start> join us . <end>',\n",
       " '<start> join us . <end>',\n",
       " '<start> keep it . <end>',\n",
       " '<start> keep it . <end>',\n",
       " '<start> keep it . <end>',\n",
       " '<start> keep it . <end>',\n",
       " '<start> keep it . <end>',\n",
       " '<start> keep it . <end>',\n",
       " '<start> kill it . <end>',\n",
       " '<start> kill it . <end>',\n",
       " '<start> kill it . <end>',\n",
       " '<start> kill it . <end>',\n",
       " '<start> kiss me . <end>',\n",
       " '<start> lock it . <end>',\n",
       " '<start> lock it . <end>',\n",
       " '<start> lock it . <end>',\n",
       " '<start> lock it . <end>',\n",
       " '<start> look up . <end>',\n",
       " '<start> look up . <end>',\n",
       " '<start> me , too . <end>',\n",
       " '<start> me , too . <end>',\n",
       " '<start> me , too . <end>',\n",
       " '<start> open it . <end>',\n",
       " '<start> open it . <end>',\n",
       " '<start> open it . <end>',\n",
       " '<start> open it . <end>',\n",
       " '<start> open it . <end>',\n",
       " '<start> open up . <end>',\n",
       " '<start> open up . <end>',\n",
       " '<start> perfect ! <end>',\n",
       " '<start> perfect ! <end>',\n",
       " '<start> perfect ! <end>',\n",
       " '<start> pull it . <end>',\n",
       " '<start> quit it ! <end>',\n",
       " '<start> quiz me . <end>',\n",
       " '<start> see you ! <end>',\n",
       " '<start> see you . <end>',\n",
       " '<start> show me . <end>',\n",
       " '<start> show me . <end>',\n",
       " '<start> show me . <end>',\n",
       " '<start> show me . <end>',\n",
       " '<start> show me . <end>',\n",
       " '<start> show me . <end>',\n",
       " '<start> shut up ! <end>',\n",
       " '<start> shut up ! <end>',\n",
       " '<start> shut up ! <end>',\n",
       " '<start> shut up ! <end>',\n",
       " '<start> shut up ! <end>',\n",
       " '<start> skip it . <end>',\n",
       " '<start> skip it . <end>',\n",
       " '<start> so long . <end>',\n",
       " '<start> stop it . <end>',\n",
       " '<start> stop it . <end>',\n",
       " '<start> stop it . <end>',\n",
       " '<start> stop it . <end>',\n",
       " '<start> stop it . <end>',\n",
       " '<start> take it . <end>',\n",
       " '<start> tell me . <end>',\n",
       " '<start> tell me . <end>',\n",
       " '<start> tom ate . <end>',\n",
       " '<start> tom ate . <end>',\n",
       " '<start> tom ran . <end>',\n",
       " '<start> tom won . <end>',\n",
       " '<start> tom won . <end>',\n",
       " '<start> wake up ! <end>',\n",
       " '<start> wake up ! <end>',\n",
       " '<start> wake up ! <end>',\n",
       " '<start> wake up ! <end>',\n",
       " '<start> wake up ! <end>',\n",
       " '<start> wake up ! <end>',\n",
       " '<start> wake up ! <end>',\n",
       " '<start> wake up . <end>',\n",
       " '<start> wake up . <end>',\n",
       " '<start> wake up . <end>',\n",
       " '<start> wake up . <end>',\n",
       " '<start> wake up . <end>',\n",
       " '<start> wake up . <end>',\n",
       " '<start> wake up . <end>',\n",
       " '<start> wake up . <end>',\n",
       " '<start> wash up . <end>',\n",
       " '<start> we care . <end>',\n",
       " '<start> we know . <end>',\n",
       " '<start> we know . <end>',\n",
       " '<start> we know . <end>',\n",
       " '<start> we lost . <end>',\n",
       " '<start> who ate ? <end>',\n",
       " '<start> who ran ? <end>',\n",
       " '<start> who won ? <end>',\n",
       " '<start> who won ? <end>',\n",
       " '<start> why not ? <end>',\n",
       " '<start> why not ? <end>',\n",
       " '<start> you run . <end>',\n",
       " '<start> you win . <end>',\n",
       " '<start> you won . <end>',\n",
       " '<start> you won . <end>',\n",
       " '<start> you won . <end>',\n",
       " '<start> you won . <end>',\n",
       " '<start> you won . <end>',\n",
       " '<start> you won . <end>',\n",
       " '<start> am i fat ? <end>',\n",
       " '<start> am i fat ? <end>',\n",
       " '<start> ask them . <end>',\n",
       " '<start> ask them . <end>',\n",
       " '<start> ask them . <end>',\n",
       " '<start> ask them . <end>',\n",
       " '<start> ask them . <end>',\n",
       " '<start> back off ! <end>',\n",
       " '<start> back off ! <end>',\n",
       " '<start> back off . <end>',\n",
       " '<start> back off . <end>',\n",
       " '<start> back off . <end>',\n",
       " '<start> back off . <end>',\n",
       " '<start> back off . <end>',\n",
       " '<start> back off . <end>',\n",
       " '<start> back off . <end>',\n",
       " '<start> back off . <end>',\n",
       " '<start> back off . <end>',\n",
       " '<start> be a man . <end>',\n",
       " '<start> be a man . <end>',\n",
       " '<start> be brave . <end>',\n",
       " '<start> be brave . <end>',\n",
       " '<start> be brief . <end>',\n",
       " '<start> be quiet . <end>',\n",
       " '<start> be quiet . <end>',\n",
       " '<start> beats me . <end>',\n",
       " '<start> buzz off . <end>',\n",
       " '<start> bye , tom . <end>',\n",
       " '<start> call tom . <end>',\n",
       " '<start> call tom . <end>',\n",
       " '<start> call tom . <end>',\n",
       " '<start> call tom . <end>',\n",
       " '<start> catch me . <end>',\n",
       " '<start> catch me . <end>',\n",
       " '<start> catch me . <end>',\n",
       " '<start> catch me . <end>',\n",
       " '<start> cheer up ! <end>',\n",
       " '<start> cheer up ! <end>',\n",
       " '<start> cheer up . <end>',\n",
       " '<start> cheer up . <end>',\n",
       " '<start> cool off ! <end>',\n",
       " '<start> cuff him . <end>',\n",
       " '<start> cuff him . <end>',\n",
       " \"<start> don't go . <end>\",\n",
       " \"<start> don't go . <end>\",\n",
       " \"<start> don't go . <end>\",\n",
       " \"<start> don't go . <end>\",\n",
       " '<start> drink it . <end>',\n",
       " '<start> drive on . <end>',\n",
       " '<start> drive on . <end>',\n",
       " '<start> find tom . <end>',\n",
       " '<start> find tom . <end>',\n",
       " '<start> fix this . <end>',\n",
       " '<start> fix this . <end>',\n",
       " '<start> fix this . <end>',\n",
       " '<start> fix this . <end>',\n",
       " '<start> get away ! <end>',\n",
       " '<start> get away ! <end>',\n",
       " '<start> get away ! <end>',\n",
       " '<start> get away ! <end>',\n",
       " '<start> get away ! <end>',\n",
       " '<start> get away . <end>',\n",
       " '<start> get busy . <end>',\n",
       " '<start> get busy . <end>',\n",
       " '<start> get busy . <end>',\n",
       " '<start> get busy . <end>',\n",
       " '<start> get down ! <end>',\n",
       " '<start> get down . <end>',\n",
       " '<start> get down . <end>',\n",
       " '<start> get down . <end>',\n",
       " '<start> get down . <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost . <end>',\n",
       " '<start> get lost . <end>',\n",
       " '<start> get lost . <end>',\n",
       " '<start> get lost . <end>',\n",
       " '<start> get real ! <end>',\n",
       " '<start> get real . <end>',\n",
       " '<start> go ahead ! <end>',\n",
       " '<start> go ahead . <end>',\n",
       " '<start> go on in . <end>',\n",
       " '<start> go there . <end>',\n",
       " '<start> good job ! <end>',\n",
       " '<start> good job ! <end>',\n",
       " '<start> grab tom . <end>',\n",
       " '<start> grab him . <end>',\n",
       " '<start> grab him . <end>',\n",
       " '<start> have fun . <end>',\n",
       " '<start> have fun . <end>',\n",
       " '<start> he spoke . <end>',\n",
       " '<start> he spoke . <end>',\n",
       " '<start> he tried . <end>',\n",
       " '<start> he tried . <end>',\n",
       " '<start> he tried . <end>',\n",
       " \"<start> he's wet . <end>\",\n",
       " '<start> help tom . <end>',\n",
       " '<start> help tom . <end>',\n",
       " '<start> hi , guys . <end>',\n",
       " '<start> how cute ! <end>',\n",
       " '<start> how deep ? <end>',\n",
       " '<start> how rude ! <end>',\n",
       " '<start> humor me . <end>',\n",
       " '<start> humor me . <end>',\n",
       " '<start> hurry up . <end>',\n",
       " '<start> hurry up . <end>',\n",
       " '<start> hurry up . <end>',\n",
       " '<start> hurry up . <end>',\n",
       " '<start> hurry up . <end>',\n",
       " '<start> hurry up . <end>',\n",
       " '<start> hurry up . <end>',\n",
       " '<start> hurry up . <end>',\n",
       " '<start> hurry up . <end>',\n",
       " '<start> hurry up . <end>',\n",
       " '<start> hurry up . <end>',\n",
       " '<start> hurry up . <end>',\n",
       " '<start> i agreed . <end>',\n",
       " '<start> i am tom . <end>',\n",
       " '<start> i am old . <end>',\n",
       " '<start> i am old . <end>',\n",
       " '<start> i am old . <end>',\n",
       " '<start> i ate it . <end>',\n",
       " '<start> i burped . <end>',\n",
       " '<start> i can go . <end>',\n",
       " '<start> i can go . <end>',\n",
       " '<start> i danced . <end>',\n",
       " '<start> i danced . <end>',\n",
       " '<start> i did it . <end>',\n",
       " '<start> i did it . <end>',\n",
       " '<start> i failed . <end>',\n",
       " '<start> i failed . <end>',\n",
       " '<start> i gasped . <end>',\n",
       " '<start> i get by . <end>',\n",
       " '<start> i goofed . <end>',\n",
       " '<start> i goofed . <end>',\n",
       " '<start> i goofed . <end>',\n",
       " '<start> i goofed . <end>',\n",
       " '<start> i got it . <end>',\n",
       " '<start> i got it . <end>',\n",
       " '<start> i got up . <end>',\n",
       " '<start> i got up . <end>',\n",
       " '<start> i helped . <end>',\n",
       " '<start> i helped . <end>',\n",
       " '<start> i jumped . <end>',\n",
       " '<start> i jumped . <end>',\n",
       " '<start> i looked . <end>',\n",
       " '<start> i looked . <end>',\n",
       " '<start> i looked . <end>',\n",
       " '<start> i moaned . <end>',\n",
       " '<start> i nodded . <end>',\n",
       " '<start> i nodded . <end>',\n",
       " '<start> i obeyed . <end>',\n",
       " '<start> i obeyed . <end>',\n",
       " '<start> i paused . <end>',\n",
       " '<start> i paused . <end>',\n",
       " '<start> i phoned . <end>',\n",
       " '<start> i phoned . <end>',\n",
       " '<start> i prayed . <end>',\n",
       " '<start> i prayed . <end>',\n",
       " '<start> i prayed . <end>',\n",
       " '<start> i prayed . <end>',\n",
       " '<start> i refuse . <end>',\n",
       " '<start> i resign . <end>',\n",
       " '<start> i saw it . <end>',\n",
       " '<start> i saw it . <end>',\n",
       " '<start> i saw it . <end>',\n",
       " '<start> i saw it . <end>',\n",
       " '<start> i shaved . <end>',\n",
       " '<start> i sighed . <end>',\n",
       " '<start> i smiled . <end>',\n",
       " '<start> i smiled . <end>',\n",
       " '<start> i stayed . <end>',\n",
       " '<start> i stayed . <end>',\n",
       " '<start> i talked . <end>',\n",
       " '<start> i talked . <end>',\n",
       " '<start> i use it . <end>',\n",
       " '<start> i use it . <end>',\n",
       " '<start> i use it . <end>',\n",
       " '<start> i use it . <end>',\n",
       " '<start> i use it . <end>',\n",
       " '<start> i use it . <end>',\n",
       " '<start> i waited . <end>',\n",
       " '<start> i waited . <end>',\n",
       " '<start> i waited . <end>',\n",
       " '<start> i waited . <end>',\n",
       " '<start> i winked . <end>',\n",
       " '<start> i winked . <end>',\n",
       " '<start> i yawned . <end>',\n",
       " '<start> i yawned . <end>',\n",
       " \"<start> i'd wait . <end>\",\n",
       " \"<start> i'll ask . <end>\",\n",
       " \"<start> i'll die . <end>\",\n",
       " \"<start> i'll pay . <end>\",\n",
       " \"<start> i'll try . <end>\",\n",
       " \"<start> i'll try . <end>\",\n",
       " \"<start> i'll try . <end>\",\n",
       " \"<start> i'll win . <end>\",\n",
       " \"<start> i'm a dj . <end>\",\n",
       " \"<start> i'm back . <end>\",\n",
       " \"<start> i'm back . <end>\",\n",
       " \"<start> i'm back . <end>\",\n",
       " \"<start> i'm bald . <end>\",\n",
       " \"<start> i'm bald . <end>\",\n",
       " \"<start> i'm busy . <end>\",\n",
       " \"<start> i'm busy . <end>\",\n",
       " \"<start> i'm calm . <end>\",\n",
       " \"<start> i'm cold . <end>\",\n",
       " \"<start> i'm cold . <end>\",\n",
       " \"<start> i'm cold . <end>\",\n",
       " \"<start> i'm cool . <end>\",\n",
       " \"<start> i'm cool . <end>\",\n",
       " \"<start> i'm cool . <end>\",\n",
       " \"<start> i'm cool . <end>\",\n",
       " \"<start> i'm deaf . <end>\",\n",
       " \"<start> i'm deaf . <end>\",\n",
       " \"<start> i'm done . <end>\",\n",
       " \"<start> i'm done . <end>\",\n",
       " \"<start> i'm easy . <end>\",\n",
       " \"<start> i'm fair . <end>\",\n",
       " \"<start> i'm fast . <end>\",\n",
       " \"<start> i'm fast . <end>\",\n",
       " \"<start> i'm fine . <end>\",\n",
       " \"<start> i'm fine . <end>\",\n",
       " \"<start> i'm free ! <end>\",\n",
       " \"<start> i'm free ! <end>\",\n",
       " \"<start> i'm free . <end>\",\n",
       " \"<start> i'm full . <end>\",\n",
       " \"<start> i'm full . <end>\",\n",
       " \"<start> i'm full . <end>\",\n",
       " \"<start> i'm full . <end>\",\n",
       " \"<start> i'm glad . <end>\",\n",
       " \"<start> i'm glad . <end>\",\n",
       " \"<start> i'm good . <end>\",\n",
       " \"<start> i'm good . <end>\",\n",
       " \"<start> i'm here . <end>\",\n",
       " \"<start> i'm here . <end>\",\n",
       " \"<start> i'm high . <end>\",\n",
       " \"<start> i'm home . <end>\",\n",
       " \"<start> i'm hurt . <end>\",\n",
       " \"<start> i'm hurt . <end>\",\n",
       " \"<start> i'm last . <end>\",\n",
       " \"<start> i'm last . <end>\",\n",
       " \"<start> i'm late . <end>\",\n",
       " \"<start> i'm late . <end>\",\n",
       " \"<start> i'm late . <end>\",\n",
       " \"<start> i'm lazy . <end>\",\n",
       " \"<start> i'm lazy . <end>\",\n",
       " \"<start> i'm lazy . <end>\",\n",
       " \"<start> i'm lost . <end>\",\n",
       " \"<start> i'm lost . <end>\",\n",
       " \"<start> i'm lost . <end>\",\n",
       " \"<start> i'm lost . <end>\",\n",
       " \"<start> i'm mean . <end>\",\n",
       " \"<start> i'm mean . <end>\",\n",
       " \"<start> i'm mean . <end>\",\n",
       " \"<start> i'm mean . <end>\",\n",
       " \"<start> i'm mean . <end>\",\n",
       " \"<start> i'm neat . <end>\",\n",
       " \"<start> i'm neat . <end>\",\n",
       " \"<start> i'm next . <end>\",\n",
       " \"<start> i'm numb . <end>\",\n",
       " \"<start> i'm numb . <end>\",\n",
       " \"<start> i'm okay . <end>\",\n",
       " \"<start> i'm okay . <end>\",\n",
       " \"<start> i'm okay . <end>\",\n",
       " \"<start> i'm poor . <end>\",\n",
       " \"<start> i'm poor . <end>\",\n",
       " \"<start> i'm rich . <end>\",\n",
       " \"<start> i'm rich . <end>\",\n",
       " \"<start> i'm rich . <end>\",\n",
       " \"<start> i'm rich . <end>\",\n",
       " \"<start> i'm safe . <end>\",\n",
       " \"<start> i'm sick . <end>\",\n",
       " \"<start> i'm sick . <end>\",\n",
       " \"<start> i'm sick . <end>\",\n",
       " \"<start> i'm slow . <end>\",\n",
       " \"<start> i'm slow . <end>\",\n",
       " \"<start> i'm slow . <end>\",\n",
       " \"<start> i'm slow . <end>\",\n",
       " \"<start> i'm sure . <end>\",\n",
       " \"<start> i'm sure . <end>\",\n",
       " \"<start> i'm tall . <end>\",\n",
       " \"<start> i'm tall . <end>\",\n",
       " \"<start> i'm thin . <end>\",\n",
       " \"<start> i'm tidy . <end>\",\n",
       " \"<start> i'm tidy . <end>\",\n",
       " \"<start> i'm ugly . <end>\",\n",
       " \"<start> i'm ugly . <end>\",\n",
       " \"<start> i'm ugly . <end>\",\n",
       " \"<start> i'm ugly . <end>\",\n",
       " \"<start> i'm ugly . <end>\",\n",
       " \"<start> i'm warm . <end>\",\n",
       " \"<start> i'm weak . <end>\",\n",
       " \"<start> i'm weak . <end>\",\n",
       " \"<start> i'm weak . <end>\",\n",
       " \"<start> i'm weak . <end>\",\n",
       " \"<start> i'm well . <end>\",\n",
       " \"<start> i'm wise . <end>\",\n",
       " \"<start> i've won . <end>\",\n",
       " \"<start> i've won . <end>\",\n",
       " '<start> it helps . <end>',\n",
       " '<start> it hurts . <end>',\n",
       " '<start> it works . <end>',\n",
       " '<start> it works . <end>',\n",
       " \"<start> it's tom . <end>\",\n",
       " \"<start> it's big . <end>\",\n",
       " \"<start> it's fun . <end>\",\n",
       " \"<start> it's his . <end>\",\n",
       " \"<start> it's hot . <end>\",\n",
       " \"<start> it's hot . <end>\",\n",
       " \"<start> it's hot . <end>\",\n",
       " \"<start> it's hot . <end>\",\n",
       " \"<start> it's new . <end>\",\n",
       " \"<start> it's new . <end>\",\n",
       " \"<start> it's new . <end>\",\n",
       " \"<start> it's new . <end>\",\n",
       " \"<start> it's new . <end>\",\n",
       " \"<start> it's odd . <end>\",\n",
       " \"<start> it's old . <end>\",\n",
       " \"<start> it's old . <end>\",\n",
       " \"<start> it's red . <end>\",\n",
       " \"<start> it's red . <end>\",\n",
       " \"<start> it's red . <end>\",\n",
       " \"<start> it's sad . <end>\",\n",
       " \"<start> it's tea . <end>\",\n",
       " '<start> keep out . <end>',\n",
       " '<start> keep out . <end>',\n",
       " '<start> kill tom . <end>',\n",
       " '<start> kill tom . <end>',\n",
       " '<start> kiss tom . <end>',\n",
       " '<start> kiss tom . <end>',\n",
       " '<start> leave it . <end>',\n",
       " '<start> leave it . <end>',\n",
       " '<start> leave it . <end>',\n",
       " '<start> leave me . <end>',\n",
       " '<start> leave me . <end>',\n",
       " '<start> leave me . <end>',\n",
       " '<start> leave me . <end>',\n",
       " '<start> leave us . <end>',\n",
       " '<start> leave us . <end>',\n",
       " \"<start> let's go ! <end>\",\n",
       " \"<start> let's go ! <end>\",\n",
       " \"<start> let's go ! <end>\",\n",
       " \"<start> let's go ! <end>\",\n",
       " \"<start> let's go . <end>\",\n",
       " \"<start> let's go . <end>\",\n",
       " \"<start> let's go . <end>\",\n",
       " \"<start> let's go . <end>\",\n",
       " '<start> look out ! <end>',\n",
       " '<start> marry me . <end>',\n",
       " '<start> marry me . <end>',\n",
       " '<start> marry me . <end>',\n",
       " '<start> marry me . <end>',\n",
       " '<start> marry me . <end>',\n",
       " '<start> marry me . <end>',\n",
       " '<start> may i go ? <end>',\n",
       " '<start> may i go ? <end>',\n",
       " '<start> poor dog . <end>',\n",
       " '<start> run away . <end>',\n",
       " '<start> save tom . <end>',\n",
       " '<start> save tom . <end>',\n",
       " '<start> she came . <end>',\n",
       " '<start> she died . <end>',\n",
       " '<start> she left . <end>',\n",
       " '<start> she left . <end>',\n",
       " '<start> she runs . <end>',\n",
       " '<start> sit down ! <end>',\n",
       " '<start> sit down ! <end>',\n",
       " '<start> sit down ! <end>',\n",
       " '<start> sit down . <end>',\n",
       " '<start> sit down . <end>',\n",
       " '<start> sit down . <end>',\n",
       " '<start> sit down . <end>',\n",
       " '<start> sit down . <end>',\n",
       " '<start> sit here . <end>',\n",
       " '<start> sit here . <end>',\n",
       " '<start> sit here . <end>',\n",
       " '<start> sit here . <end>',\n",
       " '<start> sit here . <end>',\n",
       " '<start> smash it . <end>',\n",
       " '<start> speak up ! <end>',\n",
       " '<start> speed up . <end>',\n",
       " '<start> stand by . <end>',\n",
       " '<start> stand by . <end>',\n",
       " '<start> stand by . <end>',\n",
       " '<start> stand up ! <end>',\n",
       " '<start> stand up ! <end>',\n",
       " '<start> stand up ! <end>',\n",
       " '<start> stand up ! <end>',\n",
       " '<start> stand up ! <end>',\n",
       " '<start> stand up ! <end>',\n",
       " '<start> stand up ! <end>',\n",
       " '<start> stand up ! <end>',\n",
       " '<start> stand up . <end>',\n",
       " '<start> stand up . <end>',\n",
       " '<start> stand up . <end>',\n",
       " '<start> stay put . <end>',\n",
       " '<start> stop tom . <end>',\n",
       " '<start> stop tom . <end>',\n",
       " '<start> take tom . <end>',\n",
       " '<start> taste it . <end>',\n",
       " '<start> taste it . <end>',\n",
       " '<start> taste it . <end>',\n",
       " '<start> taste it . <end>',\n",
       " '<start> tell tom . <end>',\n",
       " '<start> tell tom . <end>',\n",
       " '<start> tell tom . <end>',\n",
       " '<start> tell tom . <end>',\n",
       " '<start> terrific ! <end>',\n",
       " '<start> terrific ! <end>',\n",
       " '<start> terrific ! <end>',\n",
       " '<start> terrific ! <end>',\n",
       " '<start> they won . <end>',\n",
       " '<start> they won . <end>',\n",
       " '<start> they won . <end>',\n",
       " '<start> they won . <end>',\n",
       " '<start> tom came . <end>',\n",
       " '<start> tom came . <end>',\n",
       " '<start> tom died . <end>',\n",
       " '<start> tom fell . <end>',\n",
       " '<start> tom knew . <end>',\n",
       " '<start> tom left . <end>',\n",
       " '<start> tom left . <end>',\n",
       " '<start> tom lied . <end>',\n",
       " '<start> tom lied . <end>',\n",
       " '<start> tom lies . <end>',\n",
       " '<start> tom lies . <end>',\n",
       " '<start> tom lost . <end>',\n",
       " '<start> tom paid . <end>',\n",
       " '<start> tom quit . <end>',\n",
       " '<start> tom sang . <end>',\n",
       " '<start> tom swam . <end>',\n",
       " '<start> tom went . <end>',\n",
       " '<start> tom went . <end>',\n",
       " '<start> tom wept . <end>',\n",
       " '<start> too late . <end>',\n",
       " '<start> touch it . <end>',\n",
       " '<start> touch it . <end>',\n",
       " '<start> touch it . <end>',\n",
       " '<start> touch it . <end>',\n",
       " '<start> touch it . <end>',\n",
       " '<start> touch it . <end>',\n",
       " '<start> touch it . <end>',\n",
       " '<start> touch it . <end>',\n",
       " '<start> trust me ! <end>',\n",
       " '<start> trust me ! <end>',\n",
       " '<start> trust me . <end>',\n",
       " '<start> trust me . <end>',\n",
       " '<start> trust me . <end>',\n",
       " '<start> trust me . <end>',\n",
       " '<start> trust me . <end>',\n",
       " '<start> try hard . <end>',\n",
       " '<start> try some . <end>',\n",
       " '<start> try this . <end>',\n",
       " '<start> try this . <end>',\n",
       " '<start> try this . <end>',\n",
       " '<start> use this . <end>',\n",
       " '<start> warn tom . <end>',\n",
       " '<start> warn tom . <end>',\n",
       " '<start> we agree . <end>',\n",
       " '<start> we cried . <end>',\n",
       " '<start> we moved . <end>',\n",
       " '<start> we tried . <end>',\n",
       " '<start> we tried . <end>',\n",
       " \"<start> we'll go . <end>\",\n",
       " \"<start> we'll go . <end>\",\n",
       " \"<start> we'll go . <end>\",\n",
       " \"<start> we're ok . <end>\",\n",
       " '<start> what for ? <end>',\n",
       " '<start> what for ? <end>',\n",
       " '<start> what for ? <end>',\n",
       " '<start> what fun ! <end>',\n",
       " '<start> who came ? <end>',\n",
       " '<start> who died ? <end>',\n",
       " '<start> who fell ? <end>',\n",
       " '<start> who lost ? <end>',\n",
       " '<start> who paid ? <end>',\n",
       " '<start> who quit ? <end>',\n",
       " '<start> who quit ? <end>',\n",
       " '<start> who swam ? <end>',\n",
       " '<start> write me . <end>',\n",
       " '<start> write me . <end>',\n",
       " '<start> write me . <end>',\n",
       " '<start> write me . <end>',\n",
       " '<start> you lost . <end>',\n",
       " '<start> you lost . <end>',\n",
       " '<start> you lost . <end>',\n",
       " '<start> after you . <end>',\n",
       " '<start> after you . <end>',\n",
       " '<start> after you . <end>',\n",
       " '<start> aim . fire ! <end>',\n",
       " '<start> aim . fire ! <end>',\n",
       " '<start> am i dead ? <end>',\n",
       " '<start> am i late ? <end>',\n",
       " '<start> am i late ? <end>',\n",
       " '<start> answer me . <end>',\n",
       " '<start> answer me . <end>',\n",
       " '<start> answer me . <end>',\n",
       " '<start> answer me . <end>',\n",
       " '<start> apologize . <end>',\n",
       " '<start> apologize . <end>',\n",
       " '<start> apologize . <end>',\n",
       " '<start> apologize . <end>',\n",
       " '<start> apologize . <end>',\n",
       " '<start> apologize . <end>',\n",
       " '<start> be honest . <end>',\n",
       " '<start> be honest . <end>',\n",
       " '<start> be strong . <end>',\n",
       " '<start> be strong . <end>',\n",
       " '<start> be strong . <end>',\n",
       " ...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bf5163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "396050dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "  # creating cleaned input, output pairs\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fa29730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451436, 451436)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en), len(ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7550146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 100000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "672d5523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 80000 20000 20000\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ccca6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b481aaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "13 ----> мы\n",
      "88 ----> были\n",
      "616 ----> счастливы\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "17 ----> we\n",
      "79 ----> were\n",
      "131 ----> happy\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8de276ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 300\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46e7d850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 15]), TensorShape([64, 11]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eae823b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=False,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    \n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd5692e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "# print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29fdf920",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e621d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "decoder_sample_x, decoder_sample_h = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52951e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 7335])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_sample_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63761e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 1024])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_sample_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ee22888",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f835b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_nmt_checkpoints'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5eeef257",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "            predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e2ee081",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.7285\n",
      "Epoch 1 Batch 100 Loss 2.0302\n",
      "Epoch 1 Batch 200 Loss 1.8823\n",
      "Epoch 1 Batch 300 Loss 1.6206\n",
      "Epoch 1 Batch 400 Loss 1.5212\n",
      "Epoch 1 Batch 500 Loss 1.3477\n",
      "Epoch 1 Batch 600 Loss 1.2831\n",
      "Epoch 1 Batch 700 Loss 1.2307\n",
      "Epoch 1 Batch 800 Loss 1.2361\n",
      "Epoch 1 Batch 900 Loss 1.1497\n",
      "Epoch 1 Batch 1000 Loss 1.1108\n",
      "Epoch 1 Batch 1100 Loss 1.0012\n",
      "Epoch 1 Batch 1200 Loss 1.1429\n",
      "Epoch 1 Loss 1.4017\n",
      "Time taken for 1 epoch 1307.419626712799 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.8550\n",
      "Epoch 2 Batch 100 Loss 0.8577\n",
      "Epoch 2 Batch 200 Loss 0.7914\n",
      "Epoch 2 Batch 300 Loss 0.7636\n",
      "Epoch 2 Batch 400 Loss 0.8178\n",
      "Epoch 2 Batch 500 Loss 0.8123\n",
      "Epoch 2 Batch 600 Loss 0.6648\n",
      "Epoch 2 Batch 700 Loss 0.6588\n",
      "Epoch 2 Batch 800 Loss 0.7486\n",
      "Epoch 2 Batch 900 Loss 0.7269\n",
      "Epoch 2 Batch 1000 Loss 0.6116\n",
      "Epoch 2 Batch 1100 Loss 0.5634\n",
      "Epoch 2 Batch 1200 Loss 0.6617\n",
      "Epoch 2 Loss 0.7133\n",
      "Time taken for 1 epoch 1317.9228885173798 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.4588\n",
      "Epoch 3 Batch 100 Loss 0.4522\n",
      "Epoch 3 Batch 200 Loss 0.4143\n",
      "Epoch 3 Batch 300 Loss 0.4559\n",
      "Epoch 3 Batch 400 Loss 0.4537\n",
      "Epoch 3 Batch 500 Loss 0.3977\n",
      "Epoch 3 Batch 600 Loss 0.3670\n",
      "Epoch 3 Batch 700 Loss 0.3678\n",
      "Epoch 3 Batch 800 Loss 0.3866\n",
      "Epoch 3 Batch 900 Loss 0.4148\n",
      "Epoch 3 Batch 1000 Loss 0.3769\n",
      "Epoch 3 Batch 1100 Loss 0.3357\n",
      "Epoch 3 Batch 1200 Loss 0.3198\n",
      "Epoch 3 Loss 0.3980\n",
      "Time taken for 1 epoch 1294.713766336441 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.2093\n",
      "Epoch 4 Batch 100 Loss 0.2171\n",
      "Epoch 4 Batch 200 Loss 0.2268\n",
      "Epoch 4 Batch 300 Loss 0.2462\n",
      "Epoch 4 Batch 400 Loss 0.2845\n",
      "Epoch 4 Batch 500 Loss 0.2527\n",
      "Epoch 4 Batch 600 Loss 0.2775\n",
      "Epoch 4 Batch 700 Loss 0.2834\n",
      "Epoch 4 Batch 800 Loss 0.2571\n",
      "Epoch 4 Batch 900 Loss 0.2584\n",
      "Epoch 4 Batch 1000 Loss 0.2529\n",
      "Epoch 4 Batch 1100 Loss 0.2364\n",
      "Epoch 4 Batch 1200 Loss 0.2573\n",
      "Epoch 4 Loss 0.2417\n",
      "Time taken for 1 epoch 1251.5821776390076 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.1265\n",
      "Epoch 5 Batch 100 Loss 0.1372\n",
      "Epoch 5 Batch 200 Loss 0.1841\n",
      "Epoch 5 Batch 300 Loss 0.1360\n",
      "Epoch 5 Batch 400 Loss 0.1692\n",
      "Epoch 5 Batch 500 Loss 0.1428\n",
      "Epoch 5 Batch 600 Loss 0.1442\n",
      "Epoch 5 Batch 700 Loss 0.2012\n",
      "Epoch 5 Batch 800 Loss 0.2030\n",
      "Epoch 5 Batch 900 Loss 0.1618\n",
      "Epoch 5 Batch 1000 Loss 0.1785\n",
      "Epoch 5 Batch 1100 Loss 0.1721\n",
      "Epoch 5 Batch 1200 Loss 0.1930\n",
      "Epoch 5 Loss 0.1660\n",
      "Time taken for 1 epoch 1402.397501707077 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.1384\n",
      "Epoch 6 Batch 100 Loss 0.1007\n",
      "Epoch 6 Batch 200 Loss 0.1129\n",
      "Epoch 6 Batch 300 Loss 0.0860\n",
      "Epoch 6 Batch 400 Loss 0.1021\n",
      "Epoch 6 Batch 500 Loss 0.1083\n",
      "Epoch 6 Batch 600 Loss 0.1096\n",
      "Epoch 6 Batch 700 Loss 0.1112\n",
      "Epoch 6 Batch 800 Loss 0.1802\n",
      "Epoch 6 Batch 900 Loss 0.1149\n",
      "Epoch 6 Batch 1000 Loss 0.1465\n",
      "Epoch 6 Batch 1100 Loss 0.1529\n",
      "Epoch 6 Batch 1200 Loss 0.1432\n",
      "Epoch 6 Loss 0.1265\n",
      "Time taken for 1 epoch 1365.8622708320618 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1049\n",
      "Epoch 7 Batch 100 Loss 0.0973\n",
      "Epoch 7 Batch 200 Loss 0.1335\n",
      "Epoch 7 Batch 300 Loss 0.1136\n",
      "Epoch 7 Batch 400 Loss 0.0809\n",
      "Epoch 7 Batch 500 Loss 0.1175\n",
      "Epoch 7 Batch 600 Loss 0.1460\n",
      "Epoch 7 Batch 700 Loss 0.1473\n",
      "Epoch 7 Batch 800 Loss 0.1048\n",
      "Epoch 7 Batch 900 Loss 0.1218\n",
      "Epoch 7 Batch 1000 Loss 0.1795\n",
      "Epoch 7 Batch 1100 Loss 0.1211\n",
      "Epoch 7 Batch 1200 Loss 0.1162\n",
      "Epoch 7 Loss 0.1082\n",
      "Time taken for 1 epoch 1553.4340164661407 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0662\n",
      "Epoch 8 Batch 100 Loss 0.0667\n",
      "Epoch 8 Batch 200 Loss 0.0689\n",
      "Epoch 8 Batch 300 Loss 0.1002\n",
      "Epoch 8 Batch 400 Loss 0.0627\n",
      "Epoch 8 Batch 500 Loss 0.1032\n",
      "Epoch 8 Batch 600 Loss 0.0971\n",
      "Epoch 8 Batch 700 Loss 0.1124\n",
      "Epoch 8 Batch 800 Loss 0.0791\n",
      "Epoch 8 Batch 900 Loss 0.0774\n",
      "Epoch 8 Batch 1000 Loss 0.1117\n",
      "Epoch 8 Batch 1100 Loss 0.1406\n",
      "Epoch 8 Batch 1200 Loss 0.1317\n",
      "Epoch 8 Loss 0.0958\n",
      "Time taken for 1 epoch 1609.0467796325684 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0930\n",
      "Epoch 9 Batch 100 Loss 0.0540\n",
      "Epoch 9 Batch 200 Loss 0.0691\n",
      "Epoch 9 Batch 300 Loss 0.0851\n",
      "Epoch 9 Batch 400 Loss 0.0835\n",
      "Epoch 9 Batch 500 Loss 0.0479\n",
      "Epoch 9 Batch 600 Loss 0.0513\n",
      "Epoch 9 Batch 700 Loss 0.0815\n",
      "Epoch 9 Batch 800 Loss 0.0894\n",
      "Epoch 9 Batch 900 Loss 0.0700\n",
      "Epoch 9 Batch 1000 Loss 0.0992\n",
      "Epoch 9 Batch 1100 Loss 0.1320\n",
      "Epoch 9 Batch 1200 Loss 0.1326\n",
      "Epoch 9 Loss 0.0888\n",
      "Time taken for 1 epoch 1492.6205718517303 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0774\n",
      "Epoch 10 Batch 100 Loss 0.0525\n",
      "Epoch 10 Batch 200 Loss 0.0571\n",
      "Epoch 10 Batch 300 Loss 0.0548\n",
      "Epoch 10 Batch 400 Loss 0.0805\n",
      "Epoch 10 Batch 500 Loss 0.0736\n",
      "Epoch 10 Batch 600 Loss 0.0727\n",
      "Epoch 10 Batch 700 Loss 0.0790\n",
      "Epoch 10 Batch 800 Loss 0.1018\n",
      "Epoch 10 Batch 900 Loss 0.1316\n",
      "Epoch 10 Batch 1000 Loss 0.0878\n",
      "Epoch 10 Batch 1100 Loss 0.0785\n",
      "Epoch 10 Batch 1200 Loss 0.1009\n",
      "Epoch 10 Loss 0.0835\n",
      "Time taken for 1 epoch 1603.0393495559692 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.0855\n",
      "Epoch 11 Batch 100 Loss 0.0561\n",
      "Epoch 11 Batch 200 Loss 0.0653\n",
      "Epoch 11 Batch 300 Loss 0.0660\n",
      "Epoch 11 Batch 400 Loss 0.1124\n",
      "Epoch 11 Batch 500 Loss 0.0834\n",
      "Epoch 11 Batch 600 Loss 0.0807\n",
      "Epoch 11 Batch 700 Loss 0.0558\n",
      "Epoch 11 Batch 800 Loss 0.0742\n",
      "Epoch 11 Batch 900 Loss 0.0748\n",
      "Epoch 11 Batch 1000 Loss 0.0916\n",
      "Epoch 11 Batch 1100 Loss 0.0778\n",
      "Epoch 11 Batch 1200 Loss 0.0666\n",
      "Epoch 11 Loss 0.0815\n",
      "Time taken for 1 epoch 1684.1601366996765 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.0957\n",
      "Epoch 12 Batch 100 Loss 0.0804\n",
      "Epoch 12 Batch 200 Loss 0.0357\n",
      "Epoch 12 Batch 300 Loss 0.0677\n",
      "Epoch 12 Batch 400 Loss 0.0513\n",
      "Epoch 12 Batch 500 Loss 0.0994\n",
      "Epoch 12 Batch 600 Loss 0.0861\n",
      "Epoch 12 Batch 700 Loss 0.0886\n",
      "Epoch 12 Batch 800 Loss 0.0541\n",
      "Epoch 12 Batch 900 Loss 0.0914\n",
      "Epoch 12 Batch 1000 Loss 0.0914\n",
      "Epoch 12 Batch 1100 Loss 0.0867\n",
      "Epoch 12 Batch 1200 Loss 0.0905\n",
      "Epoch 12 Loss 0.0783\n",
      "Time taken for 1 epoch 1504.4041683673859 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.0669\n",
      "Epoch 13 Batch 100 Loss 0.0634\n",
      "Epoch 13 Batch 200 Loss 0.0635\n",
      "Epoch 13 Batch 300 Loss 0.0701\n",
      "Epoch 13 Batch 400 Loss 0.0699\n",
      "Epoch 13 Batch 500 Loss 0.0856\n",
      "Epoch 13 Batch 600 Loss 0.0690\n",
      "Epoch 13 Batch 700 Loss 0.0781\n",
      "Epoch 13 Batch 800 Loss 0.0648\n",
      "Epoch 13 Batch 900 Loss 0.0652\n",
      "Epoch 13 Batch 1000 Loss 0.0743\n",
      "Epoch 13 Batch 1100 Loss 0.0731\n",
      "Epoch 13 Batch 1200 Loss 0.0978\n",
      "Epoch 13 Loss 0.0766\n",
      "Time taken for 1 epoch 1652.1269271373749 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0300\n",
      "Epoch 14 Batch 100 Loss 0.0911\n",
      "Epoch 14 Batch 200 Loss 0.0534\n",
      "Epoch 14 Batch 300 Loss 0.0506\n",
      "Epoch 14 Batch 400 Loss 0.0472\n",
      "Epoch 14 Batch 500 Loss 0.0908\n",
      "Epoch 14 Batch 600 Loss 0.0951\n",
      "Epoch 14 Batch 700 Loss 0.0344\n",
      "Epoch 14 Batch 800 Loss 0.0966\n",
      "Epoch 14 Batch 900 Loss 0.0749\n",
      "Epoch 14 Batch 1000 Loss 0.0608\n",
      "Epoch 14 Batch 1100 Loss 0.0828\n",
      "Epoch 14 Batch 1200 Loss 0.1331\n",
      "Epoch 14 Loss 0.0731\n",
      "Time taken for 1 epoch 1589.008630990982 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0455\n",
      "Epoch 15 Batch 100 Loss 0.0324\n",
      "Epoch 15 Batch 200 Loss 0.0450\n",
      "Epoch 15 Batch 300 Loss 0.0610\n",
      "Epoch 15 Batch 400 Loss 0.0915\n",
      "Epoch 15 Batch 500 Loss 0.0471\n",
      "Epoch 15 Batch 600 Loss 0.0837\n",
      "Epoch 15 Batch 700 Loss 0.0737\n",
      "Epoch 15 Batch 800 Loss 0.0728\n",
      "Epoch 15 Batch 900 Loss 0.0672\n",
      "Epoch 15 Batch 1000 Loss 0.0759\n",
      "Epoch 15 Batch 1100 Loss 0.0740\n",
      "Epoch 15 Batch 1200 Loss 0.1065\n",
      "Epoch 15 Loss 0.0728\n",
      "Time taken for 1 epoch 1621.4494605064392 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0627\n",
      "Epoch 16 Batch 100 Loss 0.0765\n",
      "Epoch 16 Batch 200 Loss 0.0648\n",
      "Epoch 16 Batch 300 Loss 0.0885\n",
      "Epoch 16 Batch 400 Loss 0.0631\n",
      "Epoch 16 Batch 500 Loss 0.0896\n",
      "Epoch 16 Batch 600 Loss 0.0452\n",
      "Epoch 16 Batch 700 Loss 0.0997\n",
      "Epoch 16 Batch 800 Loss 0.0957\n",
      "Epoch 16 Batch 900 Loss 0.0521\n",
      "Epoch 16 Batch 1000 Loss 0.0615\n",
      "Epoch 16 Batch 1100 Loss 0.0446\n",
      "Epoch 16 Batch 1200 Loss 0.0994\n",
      "Epoch 16 Loss 0.0706\n",
      "Time taken for 1 epoch 1554.6992404460907 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0343\n",
      "Epoch 17 Batch 100 Loss 0.0661\n",
      "Epoch 17 Batch 200 Loss 0.0572\n",
      "Epoch 17 Batch 300 Loss 0.1126\n",
      "Epoch 17 Batch 400 Loss 0.0340\n",
      "Epoch 17 Batch 500 Loss 0.0576\n",
      "Epoch 17 Batch 600 Loss 0.0722\n",
      "Epoch 17 Batch 700 Loss 0.0495\n",
      "Epoch 17 Batch 800 Loss 0.0598\n",
      "Epoch 17 Batch 900 Loss 0.0840\n",
      "Epoch 17 Batch 1000 Loss 0.0852\n",
      "Epoch 17 Batch 1100 Loss 0.0479\n",
      "Epoch 17 Batch 1200 Loss 0.0551\n",
      "Epoch 17 Loss 0.0689\n",
      "Time taken for 1 epoch 1428.2763464450836 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0694\n",
      "Epoch 18 Batch 100 Loss 0.0340\n",
      "Epoch 18 Batch 200 Loss 0.0578\n",
      "Epoch 18 Batch 300 Loss 0.0225\n",
      "Epoch 18 Batch 400 Loss 0.0698\n",
      "Epoch 18 Batch 500 Loss 0.0781\n",
      "Epoch 18 Batch 600 Loss 0.0597\n",
      "Epoch 18 Batch 700 Loss 0.0751\n",
      "Epoch 18 Batch 800 Loss 0.0712\n",
      "Epoch 18 Batch 900 Loss 0.0623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Batch 1000 Loss 0.1072\n",
      "Epoch 18 Batch 1100 Loss 0.0418\n",
      "Epoch 18 Batch 1200 Loss 0.0793\n",
      "Epoch 18 Loss 0.0680\n",
      "Time taken for 1 epoch 1566.7207083702087 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0518\n",
      "Epoch 19 Batch 100 Loss 0.0379\n",
      "Epoch 19 Batch 200 Loss 0.0580\n",
      "Epoch 19 Batch 300 Loss 0.0827\n",
      "Epoch 19 Batch 400 Loss 0.0661\n",
      "Epoch 19 Batch 500 Loss 0.0660\n",
      "Epoch 19 Batch 600 Loss 0.0687\n",
      "Epoch 19 Batch 700 Loss 0.0714\n",
      "Epoch 19 Batch 800 Loss 0.0563\n",
      "Epoch 19 Batch 900 Loss 0.0627\n",
      "Epoch 19 Batch 1000 Loss 0.0650\n",
      "Epoch 19 Batch 1100 Loss 0.0704\n",
      "Epoch 19 Batch 1200 Loss 0.1471\n",
      "Epoch 19 Loss 0.0671\n",
      "Time taken for 1 epoch 1522.8802633285522 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0589\n",
      "Epoch 20 Batch 100 Loss 0.0776\n",
      "Epoch 20 Batch 200 Loss 0.0482\n",
      "Epoch 20 Batch 300 Loss 0.0523\n",
      "Epoch 20 Batch 400 Loss 0.0680\n",
      "Epoch 20 Batch 500 Loss 0.0474\n",
      "Epoch 20 Batch 600 Loss 0.0565\n",
      "Epoch 20 Batch 700 Loss 0.0748\n",
      "Epoch 20 Batch 800 Loss 0.1100\n",
      "Epoch 20 Batch 900 Loss 0.0312\n",
      "Epoch 20 Batch 1000 Loss 0.0750\n",
      "Epoch 20 Batch 1100 Loss 0.1140\n",
      "Epoch 20 Batch 1200 Loss 0.0907\n",
      "Epoch 20 Loss 0.0657\n",
      "Time taken for 1 epoch 1260.9493126869202 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c779f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b51ff4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e81dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11d1ecf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x24adf533910>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e393d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> здесь хорошо . <end>\n",
      "Predicted translation: it's good here . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Здесь хорошо.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13149541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> я никогда такого не делаю . <end>\n",
      "Predicted translation: i never do that . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'Я никогда такого не делаю.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6945c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
