{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5723ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2149dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52b3d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tolstoy.txt\", 'r') as _in:\n",
    "    lines = []\n",
    "    for line in _in:\n",
    "        line = line.strip().lower()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "txt = \" \".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c24f71a",
   "metadata": {},
   "source": [
    "для ускорения сократим объём текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d1e847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "спасибо, что скачали книгу в бесплатной электронной библиотеке royallib.com: https://royallib.com все книги автора: https://royallib.com/author/tolstoy_lev.html эта же книга в других форматах: https://royallib.com/book/tolstoy_lev/voyna_i_mir_tom_1_i_2.html приятного чтения! лев толстой война и мир тома первый и второй в. шкловский «война и мир» льва толстого замысел в 1855 году появилось объявление об издании «полярной звезды». на обложке книги в круге восходящего солнца были изображены пять по \n",
      "\n",
      "Длинна первоначального текста: 1623677 символов\n",
      "Длинна сокращенного текста:405919 символов\n"
     ]
    }
   ],
   "source": [
    "print(txt[:500],'\\n')\n",
    "print(f'Длинна первоначального текста: {len(txt)} символов')\n",
    "text = txt[:len(txt)//4]\n",
    "print(f'Длинна сокращенного текста:{len(text)} символов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d1f2eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', '!', '#', '&', '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "vocab_size = len(vocab)\n",
    "vocab[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dbb2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa7e6a56",
   "metadata": {},
   "source": [
    "## Вариант рассмотренный в классе\n",
    "\n",
    "основанный на предсказании всей последовательности +1 символ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7189fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54b94e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa255e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ad8700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'спасибо, что скачали книгу в бесплатной электронной библиотеке royallib.com: https://royallib.com все'\n",
      "' книги автора: https://royallib.com/author/tolstoy_lev.html эта же книга в других форматах: https://r'\n",
      "'oyallib.com/book/tolstoy_lev/voyna_i_mir_tom_1_i_2.html приятного чтения! лев толстой война и мир том'\n",
      "'а первый и второй в.\\xa0шкловский «война и мир» льва толстого замысел в 1855 году появилось объявление о'\n",
      "'б издании «полярной звезды». на обложке книги в круге восходящего солнца были изображены пять портрет'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eb1e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95b43f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'спасибо, что скачали книгу в бесплатной электронной библиотеке royallib.com: https://royallib.com вс'\n",
      "Target data: 'пасибо, что скачали книгу в бесплатной электронной библиотеке royallib.com: https://royallib.com все'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9269880d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "buffer_size = 10000\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d85842e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "rnn_units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f7af7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9d5b4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 128)         12160     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 512)         1312768   \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 95)          48735     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,373,663\n",
      "Trainable params: 1,373,663\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99fb393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6a5850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff0e16b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "\n",
    "    num_generate = 100\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated = []\n",
    "\n",
    "    temperature = 0.5\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cc61285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfit(dataset, model, epochs, start_string):\n",
    "\n",
    "    for iteration in range(epochs):\n",
    "        print(\"=\" * 50)\n",
    "        print(\"iteration #: %d\" % (iteration))\n",
    "        model.fit(dataset, epochs=1)\n",
    "        if (iteration+1)%10==0:\n",
    "            print(\"Start_string: %s\" % (start_string))\n",
    "            print(generate_text(model, start_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfe3f32d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "iteration #: 0\n",
      "62/62 [==============================] - 60s 925ms/step - loss: 3.4954\n",
      "==================================================\n",
      "iteration #: 1\n",
      "62/62 [==============================] - 58s 928ms/step - loss: 2.9205\n",
      "==================================================\n",
      "iteration #: 2\n",
      "62/62 [==============================] - 57s 916ms/step - loss: 2.6236\n",
      "==================================================\n",
      "iteration #: 3\n",
      "62/62 [==============================] - 59s 937ms/step - loss: 2.5039\n",
      "==================================================\n",
      "iteration #: 4\n",
      "62/62 [==============================] - 57s 920ms/step - loss: 2.4052\n",
      "==================================================\n",
      "iteration #: 5\n",
      "62/62 [==============================] - 58s 924ms/step - loss: 2.3119\n",
      "==================================================\n",
      "iteration #: 6\n",
      "62/62 [==============================] - 57s 911ms/step - loss: 2.2276\n",
      "==================================================\n",
      "iteration #: 7\n",
      "62/62 [==============================] - 60s 968ms/step - loss: 2.1529\n",
      "==================================================\n",
      "iteration #: 8\n",
      "62/62 [==============================] - 61s 975ms/step - loss: 2.0893\n",
      "==================================================\n",
      "iteration #: 9\n",
      "62/62 [==============================] - 60s 965ms/step - loss: 2.0305\n",
      "Start_string: выхожу один я на дорогу\n",
      "выхожу один я на дорогу осто ви порыва сть грогей и вели пора, уй по о в вовы нали мазана ко вала стоты во застота оразани \n",
      "==================================================\n",
      "iteration #: 10\n",
      "62/62 [==============================] - 59s 952ms/step - loss: 1.9768\n",
      "==================================================\n",
      "iteration #: 11\n",
      "62/62 [==============================] - 59s 950ms/step - loss: 1.9288\n",
      "==================================================\n",
      "iteration #: 12\n",
      "62/62 [==============================] - 63s 1s/step - loss: 1.8844\n",
      "==================================================\n",
      "iteration #: 13\n",
      "62/62 [==============================] - 63s 1s/step - loss: 1.8439\n",
      "==================================================\n",
      "iteration #: 14\n",
      "62/62 [==============================] - 62s 993ms/step - loss: 1.8059\n",
      "==================================================\n",
      "iteration #: 15\n",
      "62/62 [==============================] - 63s 1s/step - loss: 1.7704\n",
      "==================================================\n",
      "iteration #: 16\n",
      "62/62 [==============================] - 64s 1s/step - loss: 1.7372\n",
      "==================================================\n",
      "iteration #: 17\n",
      "62/62 [==============================] - 63s 1s/step - loss: 1.7080\n",
      "==================================================\n",
      "iteration #: 18\n",
      "62/62 [==============================] - 63s 1s/step - loss: 1.6787\n",
      "==================================================\n",
      "iteration #: 19\n",
      "62/62 [==============================] - 64s 1s/step - loss: 1.6514\n",
      "Start_string: выхожу один я на дорогу\n",
      "выхожу один я на дорогу ме о хость вото и как басто гостериерерино учистость илываза, по по в нот ко во ся или нумаедоралан\n",
      "==================================================\n",
      "iteration #: 20\n",
      "62/62 [==============================] - 63s 1s/step - loss: 1.6268\n",
      "==================================================\n",
      "iteration #: 21\n",
      "62/62 [==============================] - 64s 1s/step - loss: 1.6013\n",
      "==================================================\n",
      "iteration #: 22\n",
      "62/62 [==============================] - 64s 1s/step - loss: 1.5810\n",
      "==================================================\n",
      "iteration #: 23\n",
      "62/62 [==============================] - 65s 1s/step - loss: 1.5574\n",
      "==================================================\n",
      "iteration #: 24\n",
      "62/62 [==============================] - 61s 983ms/step - loss: 1.5366\n",
      "==================================================\n",
      "iteration #: 25\n",
      "62/62 [==============================] - 61s 976ms/step - loss: 1.5167\n",
      "==================================================\n",
      "iteration #: 26\n",
      "62/62 [==============================] - 62s 999ms/step - loss: 1.4962\n",
      "==================================================\n",
      "iteration #: 27\n",
      "62/62 [==============================] - 62s 999ms/step - loss: 1.4779\n",
      "==================================================\n",
      "iteration #: 28\n",
      "62/62 [==============================] - 62s 985ms/step - loss: 1.4612\n",
      "==================================================\n",
      "iteration #: 29\n",
      "62/62 [==============================] - 61s 978ms/step - loss: 1.4410\n",
      "Start_string: выхожу один я на дорогу\n",
      "выхожу один я на дорогу о ко по вогориль прало о по и гровода — и корижа, го итв ворая мну бе оня кора идазалоть вы побора.\n",
      "==================================================\n",
      "iteration #: 30\n",
      "62/62 [==============================] - 62s 993ms/step - loss: 1.4228\n",
      "==================================================\n",
      "iteration #: 31\n",
      "62/62 [==============================] - 62s 991ms/step - loss: 1.4062\n",
      "==================================================\n",
      "iteration #: 32\n",
      "62/62 [==============================] - 60s 956ms/step - loss: 1.3890\n",
      "==================================================\n",
      "iteration #: 33\n",
      "62/62 [==============================] - 62s 1s/step - loss: 1.3730\n",
      "==================================================\n",
      "iteration #: 34\n",
      "62/62 [==============================] - 62s 986ms/step - loss: 1.3566\n",
      "==================================================\n",
      "iteration #: 35\n",
      "62/62 [==============================] - 61s 980ms/step - loss: 1.3396\n",
      "==================================================\n",
      "iteration #: 36\n",
      "62/62 [==============================] - 63s 994ms/step - loss: 1.3224\n",
      "==================================================\n",
      "iteration #: 37\n",
      "62/62 [==============================] - 61s 975ms/step - loss: 1.3061\n",
      "==================================================\n",
      "iteration #: 38\n",
      "62/62 [==============================] - 65s 1s/step - loss: 1.2907\n",
      "==================================================\n",
      "iteration #: 39\n",
      "62/62 [==============================] - 60s 961ms/step - loss: 1.2722\n",
      "Start_string: выхожу один я на дорогу\n",
      "выхожу один я на дорогу прой пора пратосто — — — поримовобо стов потано илсте стото вы столили пре сто ны и, пова остоть ст\n"
     ]
    }
   ],
   "source": [
    "myfit(dataset, model, 40, 'выхожу один я на дорогу')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271637ff",
   "metadata": {},
   "source": [
    "## Вариант 2\n",
    "\n",
    "основанный на предсказании одного (следующего) симвлола \n",
    "и в качестве эмбеддинга символов простое OHE кодирование "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54764e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length, step = 20, 1\n",
    "train_seq, label_chars = [], []\n",
    "\n",
    "for i in range(0, len(text) - seq_length, step):\n",
    "    train_seq.append(text[i: i + seq_length])\n",
    "    label_chars.append(text[i + seq_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2feecacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['спасибо, что скачали', 'пасибо, что скачали '], [' ', 'к'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq[:2], label_chars[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec97bce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([405899, 20, 95])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = []\n",
    "for seq in train_seq:\n",
    "    seq_hot = []\n",
    "    for char in seq:\n",
    "        char_hot = to_categorical(char2idx[char], num_classes=len(vocab))\n",
    "        seq_hot.append(char_hot)  \n",
    "    train.append(seq_hot)\n",
    "train = tf.convert_to_tensor(train)   \n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "735da0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([405899, 95])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = []\n",
    "for char in label_chars:\n",
    "    char_hot = to_categorical(char2idx[char], num_classes=len(vocab))    \n",
    "    label.append(char_hot)\n",
    "label = tf.convert_to_tensor(label)\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a70a3499",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        \n",
    "        tf.keras.layers.LSTM(rnn_units, input_shape=(seq_length, vocab_size),return_sequences=False),\n",
    "        tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3033522",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90d26302",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_generation = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "433d3570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_1(model, start_string):\n",
    "    test_chars = start_string[-20:]\n",
    "    text_generated = []\n",
    "    \n",
    "    \n",
    "    for i in range(len_generation):\n",
    "        X_test = []\n",
    "        seq_hot = []\n",
    "\n",
    "        for char in test_chars:\n",
    "\n",
    "\n",
    "            char_hot = to_categorical(char2idx[char], num_classes=len(vocab))\n",
    "            seq_hot.append(char_hot) \n",
    "            \n",
    "        X_test.append(seq_hot)\n",
    "        X_test = tf.convert_to_tensor(X_test)        \n",
    "        pred = model.predict(X_test, verbose=0)[0]\n",
    "        y_pred = idx2char[np.argmax(pred)]\n",
    "        text_generated.append(y_pred)\n",
    "\n",
    "        test_chars = test_chars[1:] + y_pred\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9207ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfit_1(train, label, model, epochs, start_string):\n",
    "\n",
    "    for iteration in range(epochs):\n",
    "        print(\"=\" * 50)\n",
    "        print(\"iteration #: %d\" % (iteration))\n",
    "        model.fit(x=train, y=label, batch_size=batch_size, epochs=1)\n",
    "        if (iteration+1)%2==0:\n",
    "            print(\"Start_string: %s\" % (start_string))\n",
    "            print(generate_text_1(model, start_string))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b7baeb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "iteration #: 0\n",
      "6343/6343 [==============================] - 1136s 177ms/step - loss: 2.2260\n",
      "==================================================\n",
      "iteration #: 1\n",
      "6343/6343 [==============================] - 1134s 179ms/step - loss: 1.7570\n",
      "Start_string: выхожу один я на дорогу\n",
      "выхожу один я на дорогу и приехала в гостиную и подошла к стару с своим и подошла к князю андрей с том и приемания в гостин\n",
      "==================================================\n",
      "iteration #: 2\n",
      "6343/6343 [==============================] - 1140s 180ms/step - loss: 1.5860\n",
      "==================================================\n",
      "iteration #: 3\n",
      "6343/6343 [==============================] - 1275s 201ms/step - loss: 1.4763\n",
      "Start_string: выхожу один я на дорогу\n",
      "выхожу один я на дорогу от него и отвернулась к приказанием в ответенности полкового командира приступила на коленами, подо\n",
      "==================================================\n",
      "iteration #: 4\n",
      "6343/6343 [==============================] - 1490s 235ms/step - loss: 1.3867\n",
      "==================================================\n",
      "iteration #: 5\n",
      "6343/6343 [==============================] - 1197s 189ms/step - loss: 1.3151\n",
      "Start_string: выхожу один я на дорогу\n",
      "выхожу один я на дорогу от него никого не сказал он с тогому командику, который он все с тем же выражением стояли в полково\n"
     ]
    }
   ],
   "source": [
    "model =  myfit_1(train, label, model_1, 6, 'выхожу один я на дорогу')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5344eb2c",
   "metadata": {},
   "source": [
    "## Выводы:\n",
    "\n",
    "\n",
    "1. Каждая архитектура имеет свои плюсы и минусы, и большинство задач может быть решено различными подходами и различными архитектурами. И не всегда сложная архитектура является лучшим решением.\n",
    "\n",
    "2. На мой взгляд второй вариант показал более интересный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb67bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
